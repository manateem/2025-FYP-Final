{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f44589b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [patient_id, lesion_id, smoke, drink, background_father, background_mother, age, pesticide, gender, skin_cancer_history, cancer_history, has_piped_water, has_sewage_system, fitspatrick, region, diameter_1, diameter_2, diagnostic, itch, grew, hurt, changed, bleed, elevation, img_id, biopsed]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 26 columns]\n",
      "Number of rows that contain 'UNK' but have non-empty gender: 484\n",
      "Number of rows with non-empty gender and no 'UNK': 1010\n",
      "Number of rows with empty gender and no 'UNK': 804\n",
      "Number of rows with non-empty gender and no 'UNK': 1010\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2298 entries, 0 to 2297\n",
      "Data columns (total 26 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   patient_id           2298 non-null   object \n",
      " 1   lesion_id            2298 non-null   int64  \n",
      " 2   smoke                1494 non-null   object \n",
      " 3   drink                1494 non-null   object \n",
      " 4   background_father    1480 non-null   object \n",
      " 5   background_mother    1476 non-null   object \n",
      " 6   age                  2298 non-null   int64  \n",
      " 7   pesticide            1494 non-null   object \n",
      " 8   gender               1494 non-null   object \n",
      " 9   skin_cancer_history  1494 non-null   object \n",
      " 10  cancer_history       1494 non-null   object \n",
      " 11  has_piped_water      1494 non-null   object \n",
      " 12  has_sewage_system    1494 non-null   object \n",
      " 13  fitspatrick          1494 non-null   float64\n",
      " 14  region               2298 non-null   object \n",
      " 15  diameter_1           1494 non-null   float64\n",
      " 16  diameter_2           1494 non-null   float64\n",
      " 17  diagnostic           2298 non-null   object \n",
      " 18  itch                 2298 non-null   object \n",
      " 19  grew                 2298 non-null   object \n",
      " 20  hurt                 2298 non-null   object \n",
      " 21  changed              2298 non-null   object \n",
      " 22  bleed                2298 non-null   object \n",
      " 23  elevation            2298 non-null   object \n",
      " 24  img_id               2298 non-null   object \n",
      " 25  biopsed              2298 non-null   bool   \n",
      "dtypes: bool(1), float64(3), int64(2), object(20)\n",
      "memory usage: 451.2+ KB\n",
      "None\n",
      "\n",
      "Missing Values Count:\n",
      " patient_id               0\n",
      "lesion_id                0\n",
      "smoke                  804\n",
      "drink                  804\n",
      "background_father      818\n",
      "background_mother      822\n",
      "age                      0\n",
      "pesticide              804\n",
      "gender                 804\n",
      "skin_cancer_history    804\n",
      "cancer_history         804\n",
      "has_piped_water        804\n",
      "has_sewage_system      804\n",
      "fitspatrick            804\n",
      "region                   0\n",
      "diameter_1             804\n",
      "diameter_2             804\n",
      "diagnostic               0\n",
      "itch                     0\n",
      "grew                     0\n",
      "hurt                     0\n",
      "changed                  0\n",
      "bleed                    0\n",
      "elevation                0\n",
      "img_id                   0\n",
      "biopsed                  0\n",
      "dtype: int64\n",
      "\n",
      "Summary Statistics:\n",
      "          lesion_id          age  fitspatrick   diameter_1   diameter_2\n",
      "count  2298.000000  2298.000000  1494.000000  1494.000000  1494.000000\n",
      "mean   1529.933856    60.464752     2.265730    11.897055     8.852209\n",
      "std    1196.285644    15.894866     0.729029     8.634492     5.797036\n",
      "min       6.000000     6.000000     1.000000     0.000000     0.000000\n",
      "25%     720.500000    52.000000     2.000000     7.000000     5.000000\n",
      "50%    1297.000000    62.000000     2.000000    10.000000     8.000000\n",
      "75%    1782.750000    72.000000     3.000000    15.000000    10.000000\n",
      "max    4820.000000    94.000000     6.000000   100.000000    70.000000\n",
      "\n",
      "Categorical Feature Counts:\n",
      "smoke:\n",
      "smoke\n",
      "False    1292\n",
      "NaN       804\n",
      "True      202\n",
      "Name: count, dtype: int64\n",
      "\n",
      "drink:\n",
      "drink\n",
      "False    1126\n",
      "NaN       804\n",
      "True      368\n",
      "Name: count, dtype: int64\n",
      "\n",
      "itch:\n",
      "itch\n",
      "True     1455\n",
      "False     837\n",
      "UNK         6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "grew:\n",
      "grew\n",
      "False    971\n",
      "True     925\n",
      "UNK      402\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hurt:\n",
      "hurt\n",
      "False    1891\n",
      "True      397\n",
      "UNK        10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "changed:\n",
      "changed\n",
      "False    1700\n",
      "UNK       396\n",
      "True      202\n",
      "Name: count, dtype: int64\n",
      "\n",
      "bleed:\n",
      "bleed\n",
      "False    1678\n",
      "True      614\n",
      "UNK         6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "elevation:\n",
      "elevation\n",
      "True     1433\n",
      "False     863\n",
      "UNK         2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Target Variable Distribution:\n",
      " biopsed\n",
      "True     0.583986\n",
      "False    0.416014\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Feature Correlations:\n",
      " biopsed        1.000000\n",
      "age            0.181797\n",
      "diameter_2     0.081967\n",
      "diameter_1     0.058319\n",
      "fitspatrick   -0.029193\n",
      "lesion_id     -0.526881\n",
      "Name: biopsed, dtype: float64\n",
      "\n",
      "Missing Value Counts:\n",
      "patient_id               0\n",
      "lesion_id                0\n",
      "smoke                  804\n",
      "drink                  804\n",
      "background_father      818\n",
      "background_mother      822\n",
      "age                      0\n",
      "pesticide              804\n",
      "gender                 804\n",
      "skin_cancer_history    804\n",
      "cancer_history         804\n",
      "has_piped_water        804\n",
      "has_sewage_system      804\n",
      "fitspatrick            804\n",
      "region                   0\n",
      "diameter_1             804\n",
      "diameter_2             804\n",
      "diagnostic               0\n",
      "itch                     0\n",
      "grew                     0\n",
      "hurt                     0\n",
      "changed                  0\n",
      "bleed                    0\n",
      "elevation                0\n",
      "img_id                   0\n",
      "biopsed                  0\n",
      "dtype: int64\n",
      "\n",
      "Total rows with missing values in key columns: 804\n",
      "\n",
      "Smoking Data Distribution:\n",
      " smoke\n",
      "False    1292\n",
      "NaN       804\n",
      "True      202\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\valan\\OneDrive\\Desktop\\Projects in D Science\\MANDATORY\\metadata.csv\")\n",
    "\n",
    "df_missing_gender_unk = df[\n",
    "    (df['gender'].isna() | (df['gender'] == \"\")) & \n",
    "    df.apply(lambda row: row.astype(str).str.contains(\"UNK\", case=False).any(), axis=1)\n",
    "]\n",
    "\n",
    "print(df_missing_gender_unk)\n",
    "\n",
    "# Step 1: Identify rows that contain 'UNK' in any column\n",
    "df_with_unk = df[df.apply(lambda row: row.astype(str).str.contains(\"UNK\", case=False).any(), axis=1)]\n",
    "\n",
    "# Step 2: From those rows, filter only the ones where 'gender' is NOT empty\n",
    "df_with_unk_valid_gender = df_with_unk[df_with_unk['gender'].notna() & (df_with_unk['gender'] != \"\")]\n",
    "\n",
    "# Step 3: Count and display results\n",
    "valid_count = len(df_with_unk_valid_gender)\n",
    "\n",
    "print(f\"Number of rows that contain 'UNK' but have non-empty gender: {valid_count}\")\n",
    "\n",
    "# Step 1: Remove rows where 'gender' is missing or empty\n",
    "df_filtered = df[df['gender'].notna() & (df['gender'] != \"\")]\n",
    "\n",
    "# Step 2: Remove rows where any column contains 'UNK'\n",
    "df_filtered = df_filtered[~df_filtered.apply(lambda row: row.astype(str).str.contains(\"UNK\", case=False).any(), axis=1)]\n",
    "\n",
    "# Step 3: Get the count of valid rows\n",
    "valid_row_count = len(df_filtered)\n",
    "\n",
    "print(f\"Number of rows with non-empty gender and no 'UNK': {valid_row_count}\")\n",
    "\n",
    "# Step 4: Count rows where 'gender' is empty, but do NOT contain 'UNK' anywhere else\n",
    "df_missing_gender = df[df['gender'].isna() | (df['gender'] == \"\")]\n",
    "df_missing_gender_clean = df_missing_gender[~df_missing_gender.apply(lambda row: row.astype(str).str.contains(\"UNK\", case=False).any(), axis=1)]\n",
    "\n",
    "print(f\"Number of rows with empty gender and no 'UNK': {len(df_missing_gender_clean)}\")\n",
    "\n",
    "# Step 1: Remove rows where 'gender' is missing or empty\n",
    "df_filtered = df[df['pesticide'].notna() & (df['pesticide'] != \"\")]\n",
    "\n",
    "# Step 2: Remove rows where any column contains 'UNK'\n",
    "df_filtered = df_filtered[~df_filtered.apply(lambda row: row.astype(str).str.contains(\"UNK\", case=False).any(), axis=1)]\n",
    "\n",
    "# Step 3: Get the count of valid rows\n",
    "valid_row_count = len(df_filtered)\n",
    "\n",
    "print(f\"Number of rows with non-empty gender and no 'UNK': {valid_row_count}\")\n",
    "\n",
    "### **Step 1: Inspect Basic Information** ###\n",
    "print(df.info())  # Overview of dataset structure\n",
    "print(\"\\nMissing Values Count:\\n\", df.isnull().sum())  # Count missing data for each feature\n",
    "\n",
    "### **Step 2: Summary Statistics for Numerical Features** ###\n",
    "print(\"\\nSummary Statistics:\\n\", df.describe())  # View numerical feature distributions\n",
    "\n",
    "### **Step 3: Distribution of Categorical Features** ###\n",
    "binary_cols = ['smoke', 'drink', 'itch', 'grew', 'hurt', 'changed', 'bleed', 'elevation']\n",
    "print(\"\\nCategorical Feature Counts:\")\n",
    "for col in binary_cols:\n",
    "    print(f\"{col}:\\n{df[col].value_counts(dropna=False)}\\n\")\n",
    "\n",
    "### **Step 4: Check Target Variable (`biopsed`) Distribution** ###\n",
    "print(\"\\nTarget Variable Distribution:\\n\", df['biopsed'].value_counts(normalize=True))\n",
    "\n",
    "### **Step 5: Convert `biopsed` to Numeric for Correlation Analysis** ###\n",
    "df['biopsed'] = df['biopsed'].astype(int)  # Convert boolean to integer (1 = True, 0 = False)\n",
    "\n",
    "### **Step 6: Analyze Correlations (Only Numeric Features)** ###\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "print(\"\\nFeature Correlations:\\n\", df[numeric_cols].corr()['biopsed'].sort_values(ascending=False))\n",
    "\n",
    "### **Step 7: Missing Data Analysis** ###\n",
    "print(\"\\nMissing Value Counts:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check how many rows have missing values in key columns\n",
    "missing_cols = ['smoke', 'drink', 'pesticide', 'gender', 'skin_cancer_history', 'cancer_history',\n",
    "                'has_piped_water', 'has_sewage_system', 'fitspatrick', 'diameter_1', 'diameter_2']\n",
    "missing_rows = df[missing_cols].isnull().any(axis=1).sum()\n",
    "print(f\"\\nTotal rows with missing values in key columns: {missing_rows}\")\n",
    "\n",
    "# Inspect smoking data separately to confirm how missing values behave\n",
    "print(\"\\nSmoking Data Distribution:\\n\", df['smoke'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5f363326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows with missing 'smoke': 804\n",
      "Total rows with missing 'smoke' and 'biopsed' is FALSE: 804\n",
      "\n",
      "Model Accuracy (0.5 for missing binary features): 0.87\n",
      "Precision: 0.92\n",
      "Recall: 0.85\n",
      "\n",
      "Feature Importance (Odds Ratios):\n",
      "smoke: 0.09\n",
      "drink: 0.37\n",
      "itch: 1.24\n",
      "grew: 1.74\n",
      "hurt: 6.18\n",
      "changed: 20.05\n",
      "bleed: 4.71\n",
      "elevation: 2.78\n",
      "diameter_1: 1.19\n",
      "diameter_2: 1.08\n",
      "age: 1.41\n",
      "\n",
      "Cross-Validation Accuracy Scores: [0.86086957 0.85434783 0.83478261 0.87799564 0.83224401]\n",
      "Mean Accuracy: 0.85\n",
      "\n",
      "Final Missing Value Counts (After Handling):\n",
      "patient_id               0\n",
      "lesion_id                0\n",
      "smoke                    0\n",
      "drink                    0\n",
      "background_father      818\n",
      "background_mother      822\n",
      "age                      0\n",
      "pesticide              804\n",
      "gender                 804\n",
      "skin_cancer_history    804\n",
      "cancer_history         804\n",
      "has_piped_water        804\n",
      "has_sewage_system      804\n",
      "fitspatrick            804\n",
      "region                   0\n",
      "diameter_1               0\n",
      "diameter_2               0\n",
      "diagnostic               0\n",
      "itch                     0\n",
      "grew                     0\n",
      "hurt                     0\n",
      "changed                  0\n",
      "bleed                    0\n",
      "elevation                0\n",
      "img_id                   0\n",
      "biopsed                  0\n",
      "dtype: int64\n",
      "\n",
      "Total rows with missing values in key columns: 804\n",
      "\n",
      "Smoking Data Distribution (After Imputation):\n",
      " smoke\n",
      "0.0    1292\n",
      "0.5     804\n",
      "1.0     202\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valan\\AppData\\Local\\Temp\\ipykernel_14716\\1886684847.py:21: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[binary_cols] = df[binary_cols].replace({'True': 1, 'False': 0, 'UNK': np.nan}).astype(float)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\valan\\OneDrive\\Desktop\\Projects in D Science\\MANDATORY\\metadata.csv\")\n",
    "\n",
    "print(f\"Total rows with missing 'smoke': {df['smoke'].isnull().sum()}\")\n",
    "print(f\"Total rows with missing 'smoke' and 'biopsed' is FALSE: {df[df['smoke'].isnull() & (df['biopsed'] == 0)].shape[0]}\")\n",
    "\n",
    "### **DATA PREPROCESSING** ###\n",
    "\n",
    "# List of categorical features\n",
    "binary_cols = ['smoke', 'drink', 'itch', 'grew', 'hurt', 'changed', 'bleed', 'elevation']\n",
    "numeric_cols = ['diameter_1', 'diameter_2', 'age']\n",
    "\n",
    "# Convert 'UNK' to NaN, then replace True/False with 1/0\n",
    "df[binary_cols] = df[binary_cols].replace({'True': 1, 'False': 0, 'UNK': np.nan}).astype(float)\n",
    "\n",
    "# Fill missing values in binary features with 0.5 (for initial test)\n",
    "df[binary_cols] = df[binary_cols].fillna(0.5)\n",
    "\n",
    "# Fill missing values for numerical features using MEDIAN (to prevent outliers from impacting the data)\n",
    "df[numeric_cols] = df[numeric_cols].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Convert `biopsed` to numeric (1 = True, 0 = False)\n",
    "df['biopsed'] = df['biopsed'].astype(int)\n",
    "\n",
    "# Select features\n",
    "features = binary_cols + numeric_cols\n",
    "X = df[features].copy()\n",
    "y = df['biopsed']\n",
    "\n",
    "# Standardize ONLY numerical features (`diameter_1`, `diameter_2`, `age`)\n",
    "scaler = StandardScaler()\n",
    "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "\n",
    "### **TRAINING LOGISTIC REGRESSION MODEL** ###\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate Accuracy, Precision, and Recall\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "\n",
    "print(f\"\\nModel Accuracy (0.5 for missing binary features): {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "### **FEATURE IMPORTANCE** ###\n",
    "feature_importance = np.exp(model.coef_[0])  # Convert to odds ratios\n",
    "print(\"\\nFeature Importance (Odds Ratios):\")\n",
    "for feature, importance in zip(X.columns, feature_importance):\n",
    "    print(f\"{feature}: {importance:.2f}\")\n",
    "\n",
    "### **CROSS-VALIDATION** ###\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=None)\n",
    "cv_scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(f\"\\nCross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean Accuracy: {cv_scores.mean():.2f}\")\n",
    "\n",
    "### **MISSING DATA ANALYSIS** ###\n",
    "print(\"\\nFinal Missing Value Counts (After Handling):\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check total rows with missing values in key columns\n",
    "missing_cols = ['pesticide', 'gender', 'skin_cancer_history', 'cancer_history', 'has_piped_water', 'has_sewage_system', \n",
    "                'fitspatrick', 'diameter_1', 'diameter_2']\n",
    "missing_rows = df[missing_cols].isnull().any(axis=1).sum()\n",
    "\n",
    "print(f\"\\nTotal rows with missing values in key columns: {missing_rows}\")\n",
    "\n",
    "# Inspect smoking data distribution after imputation\n",
    "print(\"\\nSmoking Data Distribution (After Imputation):\\n\", df['smoke'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d71fad7",
   "metadata": {},
   "source": [
    "### Splitting the dataset to try to fix the bias of the 804 rows that miss values, and are all biopsed FALSE, which probably would cause issues for our training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bf077efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.90\n",
      "Precision: 0.90\n",
      "Recall: 1.00\n",
      "Cross-Validation Mean Accuracy: 0.89\n",
      "\n",
      "Feature Importance (Odds Ratios):\n",
      "smoke: 2.11\n",
      "drink: 0.80\n",
      "itch: 1.10\n",
      "grew: 1.73\n",
      "hurt: 4.98\n",
      "changed: 18.92\n",
      "bleed: 2.45\n",
      "elevation: 2.72\n",
      "diameter: 1.24\n",
      "Test Accuracy: 0.88\n",
      "Test Precision: 0.88\n",
      "Test Recall: 1.00\n",
      "\n",
      "Missing Value Counts in Original DataFrame:\n",
      "patient_id               0\n",
      "lesion_id                0\n",
      "smoke                    0\n",
      "drink                    0\n",
      "background_father      818\n",
      "background_mother      822\n",
      "age                      0\n",
      "pesticide              804\n",
      "gender                 804\n",
      "skin_cancer_history    804\n",
      "cancer_history         804\n",
      "has_piped_water        804\n",
      "has_sewage_system      804\n",
      "fitspatrick            804\n",
      "region                   0\n",
      "diameter_1               0\n",
      "diameter_2               0\n",
      "diagnostic               0\n",
      "itch                     0\n",
      "grew                     0\n",
      "hurt                     0\n",
      "changed                  0\n",
      "bleed                    0\n",
      "elevation                0\n",
      "img_id                   0\n",
      "biopsed                  0\n",
      "diameter                 0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valan\\AppData\\Local\\Temp\\ipykernel_14716\\2669202935.py:17: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[binary_cols] = df[binary_cols].replace({'True': 1, 'False': 0, 'UNK': np.nan})  # Convert to numeric\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Load dataset (adjust file path as needed)\n",
    "df = pd.read_csv(r\"C:\\Users\\valan\\OneDrive\\Desktop\\Projects in D Science\\MANDATORY\\metadata.csv\")\n",
    "\n",
    "# ================================\n",
    "# STEP 1: Preprocess Important Features\n",
    "# ================================\n",
    "\n",
    "# Define important binary features (we use these for the model)\n",
    "binary_cols = ['smoke', 'drink', 'itch', 'grew', 'hurt', 'changed', 'bleed', 'elevation']\n",
    "df[binary_cols] = df[binary_cols].replace({'True': 1, 'False': 0, 'UNK': np.nan})  # Convert to numeric\n",
    "df[binary_cols] = df[binary_cols].astype(float).fillna(0.5)  # Impute missing values with 0.5\n",
    "\n",
    "# Process the diameter features\n",
    "diameter_cols = ['diameter_1', 'diameter_2']\n",
    "df[diameter_cols] = df[diameter_cols].apply(lambda col: col.fillna(col.median()))  # Median imputation\n",
    "df['diameter'] = df[diameter_cols].mean(axis=1)  # Create averaged diameter feature\n",
    "\n",
    "# Convert target variable 'biopsed' to numeric (True → 1, False → 0)\n",
    "df['biopsed'] = df['biopsed'].astype(int)\n",
    "\n",
    "# ================================\n",
    "# STEP 2: Use Complete Cases for Modeling\n",
    "# ================================\n",
    "\n",
    "# Define key columns that must be present\n",
    "cols_to_clean = ['pesticide', 'gender', 'skin_cancer_history', 'cancer_history', \n",
    "                 'has_piped_water', 'has_sewage_system', 'fitspatrick', \n",
    "                 'diameter_1', 'diameter_2']\n",
    "\n",
    "# Drop rows missing values in key columns\n",
    "df_clean = df.dropna(subset=cols_to_clean)\n",
    "\n",
    "# Feature matrix & target variable\n",
    "features = binary_cols + ['diameter']\n",
    "X = df_clean[features].copy()\n",
    "y = df_clean['biopsed']\n",
    "\n",
    "# ================================\n",
    "# STEP 3: Standardize Numerical Features\n",
    "# ================================\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X[['diameter']] = scaler.fit_transform(X[['diameter']])\n",
    "\n",
    "# ================================\n",
    "# STEP 4: Training and Evaluation\n",
    "# ================================\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Model Predictions\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Accuracy Score\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Precision Score\n",
    "precision = precision_score(y, y_pred, zero_division=1)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "# Recall Score\n",
    "recall = recall_score(y, y_pred, zero_division=1)\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "# Perform Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=None)\n",
    "cv_scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "print(f\"Cross-Validation Mean Accuracy: {cv_scores.mean():.2f}\")\n",
    "\n",
    "# ================================\n",
    "# STEP 5: Feature Importance (Odds Ratios)\n",
    "# ================================\n",
    "\n",
    "odds_ratios = np.exp(model.coef_[0])\n",
    "print(\"\\nFeature Importance (Odds Ratios):\")\n",
    "for feat, ratio in zip(features, odds_ratios):\n",
    "    print(f\"{feat}: {ratio:.2f}\")\n",
    "\n",
    "# ================================\n",
    "# STEP 6: Train–Test Split & Evaluation on Hold-Out Set\n",
    "# ================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Accuracy Score\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Precision Score (on test set)\n",
    "precision_test = precision_score(y_test, y_pred_test, zero_division=1)\n",
    "print(f\"Test Precision: {precision_test:.2f}\")\n",
    "\n",
    "# Recall Score (on test set)\n",
    "recall_test = recall_score(y_test, y_pred_test, zero_division=1)\n",
    "print(f\"Test Recall: {recall_test:.2f}\")\n",
    "\n",
    "# ================================\n",
    "# STEP 7: Additional Missing Value Check\n",
    "# ================================\n",
    "\n",
    "print(\"\\nMissing Value Counts in Original DataFrame:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c560c93e",
   "metadata": {},
   "source": [
    "# **Refining the Model by Selecting Key Features**\n",
    "\n",
    "### **Selected Features**\n",
    "Based on feature importance analysis, we focus on high-impact predictors:\n",
    "\n",
    "| Feature   | Odds Ratio (First Model) | Odds Ratio (Full Model) |\n",
    "|-----------|-------------------------|-------------------------|\n",
    "| **Changed**   | 23.85 | 17.89 |\n",
    "| **Hurt**      | 7.86  | 5.08  |\n",
    "| **Bleed**     | 4.06  | 2.44  |\n",
    "| **Elevation** | 2.94  | 2.89  |\n",
    "| **Diameter**  | 1.24  | 1.26  |\n",
    "| **Age**       | 1.34  | 0.82  |\n",
    "\n",
    "### **Next Steps**\n",
    "1️⃣ **Re-train the model using only the above features**  \n",
    "2️⃣ **Compare accuracy with previous versions**  \n",
    "3️⃣ **Assess if simplifying the model improves generalization**\n",
    "\n",
    "\n",
    "### We split the data into two models before, because for the same 804 entries , we had a lot of missing values. But now that we keep the important features , only diameter has missing values so we ll fix that by using the median for the missing entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "453c0188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8173913043478261\n",
      "Precision: 0.9090909090909091\n",
      "Recall: 0.7801418439716312\n",
      "Cross-Validation Mean Accuracy: 0.8046045278014589\n",
      "\n",
      "Feature Importance (Odds Ratios):\n",
      "changed: 27.39\n",
      "hurt: 6.71\n",
      "bleed: 5.52\n",
      "elevation: 3.28\n",
      "diameter: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valan\\AppData\\Local\\Temp\\ipykernel_14716\\1283177078.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[important_binary] = df[important_binary].replace({'True': 1, 'False': 0, 'UNK': np.nan})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Load dataset (adjust file path as needed)\n",
    "df = pd.read_csv(r\"C:\\Users\\valan\\OneDrive\\Desktop\\Projects in D Science\\MANDATORY\\metadata.csv\")\n",
    "\n",
    "# ================================\n",
    "# STEP 1: Preprocess Important Features\n",
    "# ================================\n",
    "\n",
    "# Define important binary features (we use these for the model)\n",
    "important_binary = ['changed', 'hurt', 'bleed', 'elevation']\n",
    "# Replace string values: 'True' becomes 1, 'False' becomes 0, and 'UNK' becomes NaN.\n",
    "df[important_binary] = df[important_binary].replace({'True': 1, 'False': 0, 'UNK': np.nan})\n",
    "# Ensure they are floats, then fill missing values with 0.5\n",
    "df[important_binary] = df[important_binary].astype(float).fillna(0.5)\n",
    "\n",
    "# Process the diameter features.\n",
    "diameter_cols = ['diameter_1', 'diameter_2']\n",
    "# Impute missing values with the median\n",
    "df[diameter_cols] = df[diameter_cols].apply(lambda col: col.fillna(col.median()))\n",
    "# Create a new combined 'diameter' feature as the average\n",
    "df['diameter'] = df[diameter_cols].mean(axis=1)\n",
    "\n",
    "# Convert the target variable 'biopsed' to numeric (True → 1, False → 0)\n",
    "df['biopsed'] = df['biopsed'].astype(int)\n",
    "\n",
    "# ================================\n",
    "# STEP 2: Define Feature Set and Prepare Data\n",
    "# ================================\n",
    "\n",
    "# Using the four binary features + the combined diameter feature\n",
    "features = important_binary + ['diameter']\n",
    "\n",
    "# Feature matrix and target variable\n",
    "X = df[features].copy()\n",
    "y = df['biopsed']\n",
    "\n",
    "# Standardize the continuous feature \"diameter\"\n",
    "scaler = StandardScaler()\n",
    "X[['diameter']] = scaler.fit_transform(X[['diameter']])\n",
    "\n",
    "# ================================\n",
    "# STEP 3: Train/Test Split (80/20)\n",
    "# ================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ================================\n",
    "# STEP 4: Training and Evaluation\n",
    "# ================================\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Accuracy Score\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Precision Score\n",
    "precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Recall Score\n",
    "recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Perform cross-validation on the entire dataset:\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "print(\"Cross-Validation Mean Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# ================================\n",
    "# STEP 5: Feature Importance (Odds Ratios)\n",
    "# ================================\n",
    "\n",
    "odds_ratios = np.exp(model.coef_[0])\n",
    "print(\"\\nFeature Importance (Odds Ratios):\")\n",
    "for feat, ratio in zip(features, odds_ratios):\n",
    "    print(f\"{feat}: {ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b714af",
   "metadata": {},
   "source": [
    "### And a final training using only the 4 features that seem to be the most important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d53480d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8043478260869565\n",
      "Precision: 0.9137931034482759\n",
      "Recall: 0.75177304964539\n",
      "Cross-Validation Mean Accuracy: 0.7932982854977741\n",
      "\n",
      "Feature Importance (Odds Ratios):\n",
      "changed: 27.76\n",
      "hurt: 6.97\n",
      "bleed: 5.76\n",
      "elevation: 3.18\n",
      "\n",
      "Missing Value Counts in Original Data:\n",
      "patient_id               0\n",
      "lesion_id                0\n",
      "smoke                  804\n",
      "drink                  804\n",
      "background_father      818\n",
      "background_mother      822\n",
      "age                      0\n",
      "pesticide              804\n",
      "gender                 804\n",
      "skin_cancer_history    804\n",
      "cancer_history         804\n",
      "has_piped_water        804\n",
      "has_sewage_system      804\n",
      "fitspatrick            804\n",
      "region                   0\n",
      "diameter_1             804\n",
      "diameter_2             804\n",
      "diagnostic               0\n",
      "itch                     0\n",
      "grew                     0\n",
      "hurt                     0\n",
      "changed                  0\n",
      "bleed                    0\n",
      "elevation                0\n",
      "img_id                   0\n",
      "biopsed                  0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valan\\AppData\\Local\\Temp\\ipykernel_14716\\2702337137.py:16: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[important_binary] = df[important_binary].replace({'True': 1, 'False': 0, 'UNK': np.nan})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# ---------------------------\n",
    "# Load dataset (update the path as needed)\n",
    "df = pd.read_csv(r\"C:\\Users\\valan\\OneDrive\\Desktop\\Projects in D Science\\MANDATORY\\metadata.csv\")\n",
    "# ---------------------------\n",
    "\n",
    "# STEP 1: Preprocessing for the Important Binary Features\n",
    "important_binary = ['changed', 'hurt', 'bleed', 'elevation']\n",
    "\n",
    "# Replace string entries (True → 1, False → 0, 'UNK' → NaN)\n",
    "df[important_binary] = df[important_binary].replace({'True': 1, 'False': 0, 'UNK': np.nan})\n",
    "df[important_binary] = df[important_binary].astype(float).fillna(0.5)  # Impute missing values with 0.5\n",
    "\n",
    "# Convert target variable 'biopsed' to numeric (True → 1, False → 0)\n",
    "df['biopsed'] = df['biopsed'].astype(int)\n",
    "\n",
    "# STEP 2: Define Features & Prepare Dataset\n",
    "features = important_binary\n",
    "X = df[features].copy()\n",
    "y = df['biopsed']\n",
    "\n",
    "# STEP 3: Train–Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# STEP 4: Train the Logistic Regression Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# STEP 5: Evaluate the Model on the Hold-Out Test Set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Precision & Recall\n",
    "precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Also run cross-validation on the entire dataset:\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "print(\"Cross-Validation Mean Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# STEP 6: Feature Importance (Odds Ratios)\n",
    "odds_ratios = np.exp(model.coef_[0])\n",
    "print(\"\\nFeature Importance (Odds Ratios):\")\n",
    "for feat, ratio in zip(features, odds_ratios):\n",
    "    print(f\"{feat}: {ratio:.2f}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Additional analysis (optional): Check missingness in the original DataFrame\n",
    "print(\"\\nMissing Value Counts in Original Data:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7e07d9",
   "metadata": {},
   "source": [
    "### GROUPKFOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1b5dc5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valan\\AppData\\Local\\Temp\\ipykernel_14716\\3723862891.py:16: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[binary_cols] = df[binary_cols].replace({'True': 1, 'False': 0, 'UNK': np.nan}).astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Train Patients (1098): ['PAT_1516' 'PAT_1545' 'PAT_1989' ... 'PAT_273' 'PAT_491' 'PAT_1714']\n",
      "Test Patients (275): ['PAT_46' 'PAT_778' 'PAT_1995' 'PAT_705' 'PAT_2140' 'PAT_1653' 'PAT_134'\n",
      " 'PAT_1453' 'PAT_1803' 'PAT_682' 'PAT_680' 'PAT_53' 'PAT_26' 'PAT_544'\n",
      " 'PAT_2025' 'PAT_1094' 'PAT_369' 'PAT_981' 'PAT_409' 'PAT_1573' 'PAT_1109'\n",
      " 'PAT_1400' 'PAT_549' 'PAT_847' 'PAT_999' 'PAT_2154' 'PAT_207' 'PAT_514'\n",
      " 'PAT_1286' 'PAT_330' 'PAT_1062' 'PAT_2076' 'PAT_280' 'PAT_1411' 'PAT_34'\n",
      " 'PAT_1702' 'PAT_398' 'PAT_953' 'PAT_478' 'PAT_663' 'PAT_1509' 'PAT_782'\n",
      " 'PAT_257' 'PAT_397' 'PAT_185' 'PAT_1333' 'PAT_1027' 'PAT_375' 'PAT_495'\n",
      " 'PAT_587' 'PAT_364' 'PAT_39' 'PAT_59' 'PAT_338' 'PAT_1324' 'PAT_672'\n",
      " 'PAT_832' 'PAT_1364' 'PAT_192' 'PAT_831' 'PAT_291' 'PAT_346' 'PAT_372'\n",
      " 'PAT_462' 'PAT_513' 'PAT_1031' 'PAT_1729' 'PAT_510' 'PAT_1875' 'PAT_806'\n",
      " 'PAT_307' 'PAT_1042' 'PAT_1141' 'PAT_1476' 'PAT_766' 'PAT_1639'\n",
      " 'PAT_1329' 'PAT_652' 'PAT_2061' 'PAT_1374' 'PAT_235' 'PAT_490' 'PAT_171'\n",
      " 'PAT_1350' 'PAT_1122' 'PAT_1215' 'PAT_247' 'PAT_919' 'PAT_1971' 'PAT_112'\n",
      " 'PAT_44' 'PAT_1849' 'PAT_2065' 'PAT_532' 'PAT_590' 'PAT_57' 'PAT_2107'\n",
      " 'PAT_713' 'PAT_153' 'PAT_849' 'PAT_1704' 'PAT_903' 'PAT_1065' 'PAT_49'\n",
      " 'PAT_639' 'PAT_2041' 'PAT_432' 'PAT_85' 'PAT_529' 'PAT_1432' 'PAT_1978'\n",
      " 'PAT_242' 'PAT_468' 'PAT_1666' 'PAT_791' 'PAT_2006' 'PAT_220' 'PAT_382'\n",
      " 'PAT_1591' 'PAT_1171' 'PAT_540' 'PAT_744' 'PAT_71' 'PAT_1641' 'PAT_1690'\n",
      " 'PAT_184' 'PAT_640' 'PAT_1273' 'PAT_1572' 'PAT_577' 'PAT_834' 'PAT_1608'\n",
      " 'PAT_72' 'PAT_1388' 'PAT_50' 'PAT_1770' 'PAT_362' 'PAT_601' 'PAT_1020'\n",
      " 'PAT_926' 'PAT_2144' 'PAT_1944' 'PAT_1221' 'PAT_272' 'PAT_1951' 'PAT_27'\n",
      " 'PAT_2036' 'PAT_1208' 'PAT_881' 'PAT_823' 'PAT_1505' 'PAT_2092' 'PAT_610'\n",
      " 'PAT_890' 'PAT_96' 'PAT_797' 'PAT_818' 'PAT_1755' 'PAT_2024' 'PAT_2129'\n",
      " 'PAT_1739' 'PAT_900' 'PAT_504' 'PAT_1180' 'PAT_931' 'PAT_987' 'PAT_1452'\n",
      " 'PAT_210' 'PAT_559' 'PAT_428' 'PAT_2116' 'PAT_1351' 'PAT_1113' 'PAT_1118'\n",
      " 'PAT_874' 'PAT_156' 'PAT_660' 'PAT_1373' 'PAT_2017' 'PAT_1946' 'PAT_815'\n",
      " 'PAT_1450' 'PAT_451' 'PAT_1469' 'PAT_447' 'PAT_894' 'PAT_2081' 'PAT_357'\n",
      " 'PAT_176' 'PAT_1269' 'PAT_896' 'PAT_355' 'PAT_472' 'PAT_1129' 'PAT_158'\n",
      " 'PAT_1861' 'PAT_598' 'PAT_727' 'PAT_1313' 'PAT_567' 'PAT_2124' 'PAT_420'\n",
      " 'PAT_1624' 'PAT_1158' 'PAT_1480' 'PAT_1494' 'PAT_707' 'PAT_271'\n",
      " 'PAT_1376' 'PAT_2160' 'PAT_1620' 'PAT_734' 'PAT_205' 'PAT_758' 'PAT_1174'\n",
      " 'PAT_489' 'PAT_1614' 'PAT_1899' 'PAT_120' 'PAT_1190' 'PAT_971' 'PAT_1633'\n",
      " 'PAT_91' 'PAT_274' 'PAT_1299' 'PAT_1810' 'PAT_1018' 'PAT_1798' 'PAT_323'\n",
      " 'PAT_1906' 'PAT_857' 'PAT_1786' 'PAT_686' 'PAT_628' 'PAT_1245' 'PAT_912'\n",
      " 'PAT_480' 'PAT_1718' 'PAT_1581' 'PAT_1136' 'PAT_193' 'PAT_1312'\n",
      " 'PAT_1223' 'PAT_720' 'PAT_84' 'PAT_1301' 'PAT_1401' 'PAT_248' 'PAT_992'\n",
      " 'PAT_317' 'PAT_1303' 'PAT_404' 'PAT_455' 'PAT_172' 'PAT_781' 'PAT_78'\n",
      " 'PAT_81' 'PAT_1148' 'PAT_1983' 'PAT_148' 'PAT_889' 'PAT_553' 'PAT_1455'\n",
      " 'PAT_763' 'PAT_1219' 'PAT_1655' 'PAT_913' 'PAT_619' 'PAT_693' 'PAT_1341'\n",
      " 'PAT_774' 'PAT_1757' 'PAT_136' 'PAT_414' 'PAT_1343']\n",
      "Fold Accuracy: 0.8739, Fold Precision: 0.9031, Fold Recall: 0.8759\n",
      "\n",
      "Fold 2\n",
      "Train Patients (1098): ['PAT_1516' 'PAT_46' 'PAT_1545' ... 'PAT_491' 'PAT_1343' 'PAT_1714']\n",
      "Test Patients (275): ['PAT_1989' 'PAT_435' 'PAT_302' 'PAT_1582' 'PAT_944' 'PAT_793' 'PAT_394'\n",
      " 'PAT_374' 'PAT_1074' 'PAT_805' 'PAT_920' 'PAT_411' 'PAT_692' 'PAT_963'\n",
      " 'PAT_1725' 'PAT_98' 'PAT_276' 'PAT_430' 'PAT_419' 'PAT_1423' 'PAT_1414'\n",
      " 'PAT_377' 'PAT_962' 'PAT_492' 'PAT_966' 'PAT_461' 'PAT_1721' 'PAT_426'\n",
      " 'PAT_958' 'PAT_1305' 'PAT_1546' 'PAT_413' 'PAT_1728' 'PAT_396' 'PAT_216'\n",
      " 'PAT_1277' 'PAT_361' 'PAT_1316' 'PAT_300' 'PAT_82' 'PAT_54' 'PAT_547'\n",
      " 'PAT_221' 'PAT_803' 'PAT_385' 'PAT_721' 'PAT_316' 'PAT_842' 'PAT_1460'\n",
      " 'PAT_880' 'PAT_21' 'PAT_839' 'PAT_1481' 'PAT_665' 'PAT_976' 'PAT_1764'\n",
      " 'PAT_535' 'PAT_1583' 'PAT_524' 'PAT_576' 'PAT_1128' 'PAT_485' 'PAT_340'\n",
      " 'PAT_1981' 'PAT_315' 'PAT_1914' 'PAT_908' 'PAT_1665' 'PAT_500' 'PAT_259'\n",
      " 'PAT_728' 'PAT_895' 'PAT_545' 'PAT_439' 'PAT_108' 'PAT_354' 'PAT_1393'\n",
      " 'PAT_923' 'PAT_1256' 'PAT_731' 'PAT_128' 'PAT_1769' 'PAT_503' 'PAT_217'\n",
      " 'PAT_2071' 'PAT_673' 'PAT_597' 'PAT_1762' 'PAT_2143' 'PAT_191' 'PAT_87'\n",
      " 'PAT_1197' 'PAT_279' 'PAT_822' 'PAT_388' 'PAT_1119' 'PAT_712' 'PAT_860'\n",
      " 'PAT_1420' 'PAT_512' 'PAT_1483' 'PAT_957' 'PAT_1874' 'PAT_1498' 'PAT_433'\n",
      " 'PAT_749' 'PAT_1738' 'PAT_456' 'PAT_637' 'PAT_704' 'PAT_1072' 'PAT_237'\n",
      " 'PAT_1600' 'PAT_61' 'PAT_2106' 'PAT_356' 'PAT_703' 'PAT_305' 'PAT_204'\n",
      " 'PAT_470' 'PAT_1403' 'PAT_537' 'PAT_755' 'PAT_198' 'PAT_297' 'PAT_1252'\n",
      " 'PAT_1689' 'PAT_1503' 'PAT_876' 'PAT_824' 'PAT_1586' 'PAT_859' 'PAT_246'\n",
      " 'PAT_16' 'PAT_75' 'PAT_641' 'PAT_403' 'PAT_1130' 'PAT_1846' 'PAT_625'\n",
      " 'PAT_609' 'PAT_1090' 'PAT_1371' 'PAT_212' 'PAT_773' 'PAT_1780' 'PAT_921'\n",
      " 'PAT_633' 'PAT_816' 'PAT_1216' 'PAT_123' 'PAT_142' 'PAT_845' 'PAT_29'\n",
      " 'PAT_789' 'PAT_1408' 'PAT_914' 'PAT_494' 'PAT_2090' 'PAT_2049' 'PAT_1605'\n",
      " 'PAT_1650' 'PAT_1557' 'PAT_658' 'PAT_1801' 'PAT_104' 'PAT_1367' 'PAT_993'\n",
      " 'PAT_268' 'PAT_173' 'PAT_651' 'PAT_163' 'PAT_1800' 'PAT_1577' 'PAT_1893'\n",
      " 'PAT_1486' 'PAT_2153' 'PAT_638' 'PAT_1296' 'PAT_460' 'PAT_2099' 'PAT_873'\n",
      " 'PAT_1138' 'PAT_2003' 'PAT_88' 'PAT_615' 'PAT_299' 'PAT_762' 'PAT_669'\n",
      " 'PAT_885' 'PAT_363' 'PAT_983' 'PAT_2161' 'PAT_1176' 'PAT_523' 'PAT_897'\n",
      " 'PAT_1937' 'PAT_1528' 'PAT_1433' 'PAT_201' 'PAT_1229' 'PAT_119'\n",
      " 'PAT_1615' 'PAT_1535' 'PAT_2022' 'PAT_622' 'PAT_442' 'PAT_2128'\n",
      " 'PAT_2113' 'PAT_186' 'PAT_422' 'PAT_1344' 'PAT_1105' 'PAT_519' 'PAT_1335'\n",
      " 'PAT_1907' 'PAT_1127' 'PAT_583' 'PAT_345' 'PAT_737' 'PAT_612' 'PAT_1172'\n",
      " 'PAT_945' 'PAT_780' 'PAT_321' 'PAT_1259' 'PAT_1267' 'PAT_1749' 'PAT_262'\n",
      " 'PAT_888' 'PAT_998' 'PAT_178' 'PAT_980' 'PAT_718' 'PAT_1673' 'PAT_618'\n",
      " 'PAT_1814' 'PAT_1331' 'PAT_1102' 'PAT_1000' 'PAT_1317' 'PAT_1596'\n",
      " 'PAT_2115' 'PAT_2080' 'PAT_1443' 'PAT_1222' 'PAT_31' 'PAT_2056' 'PAT_568'\n",
      " 'PAT_1320' 'PAT_829' 'PAT_662' 'PAT_445' 'PAT_14' 'PAT_1274' 'PAT_1928'\n",
      " 'PAT_1310' 'PAT_1209' 'PAT_454' 'PAT_1969' 'PAT_1202' 'PAT_2013'\n",
      " 'PAT_2123' 'PAT_1571' 'PAT_1787' 'PAT_943' 'PAT_1734' 'PAT_389'\n",
      " 'PAT_1696' 'PAT_1838' 'PAT_973' 'PAT_1540' 'PAT_1429' 'PAT_739' 'PAT_681']\n",
      "Fold Accuracy: 0.8630, Fold Precision: 0.8832, Fold Recall: 0.8864\n",
      "\n",
      "Fold 3\n",
      "Train Patients (1098): ['PAT_46' 'PAT_1545' 'PAT_1989' ... 'PAT_414' 'PAT_273' 'PAT_1343']\n",
      "Test Patients (275): ['PAT_1516' 'PAT_684' 'PAT_2088' 'PAT_1783' 'PAT_106' 'PAT_359' 'PAT_1926'\n",
      " 'PAT_265' 'PAT_2020' 'PAT_868' 'PAT_183' 'PAT_333' 'PAT_867' 'PAT_1014'\n",
      " 'PAT_701' 'PAT_795' 'PAT_288' 'PAT_645' 'PAT_241' 'PAT_995' 'PAT_1070'\n",
      " 'PAT_1688' 'PAT_1210' 'PAT_263' 'PAT_168' 'PAT_441' 'PAT_2127' 'PAT_722'\n",
      " 'PAT_162' 'PAT_1794' 'PAT_267' 'PAT_395' 'PAT_306' 'PAT_985' 'PAT_466'\n",
      " 'PAT_1955' 'PAT_997' 'PAT_228' 'PAT_1871' 'PAT_699' 'PAT_1942' 'PAT_412'\n",
      " 'PAT_526' 'PAT_730' 'PAT_948' 'PAT_827' 'PAT_1461' 'PAT_614' 'PAT_2122'\n",
      " 'PAT_93' 'PAT_1661' 'PAT_1428' 'PAT_1682' 'PAT_131' 'PAT_170' 'PAT_551'\n",
      " 'PAT_738' 'PAT_286' 'PAT_522' 'PAT_1826' 'PAT_1993' 'PAT_493' 'PAT_631'\n",
      " 'PAT_2010' 'PAT_879' 'PAT_74' 'PAT_1257' 'PAT_2048' 'PAT_1304' 'PAT_425'\n",
      " 'PAT_1881' 'PAT_1139' 'PAT_92' 'PAT_1733' 'PAT_531' 'PAT_1813' 'PAT_689'\n",
      " 'PAT_853' 'PAT_1956' 'PAT_211' 'PAT_975' 'PAT_1243' 'PAT_73' 'PAT_858'\n",
      " 'PAT_930' 'PAT_1526' 'PAT_1588' 'PAT_224' 'PAT_1550' 'PAT_1035' 'PAT_378'\n",
      " 'PAT_1648' 'PAT_1265' 'PAT_2016' 'PAT_1866' 'PAT_539' 'PAT_1903'\n",
      " 'PAT_301' 'PAT_872' 'PAT_65' 'PAT_924' 'PAT_40' 'PAT_227' 'PAT_202'\n",
      " 'PAT_761' 'PAT_630' 'PAT_582' 'PAT_951' 'PAT_570' 'PAT_1597' 'PAT_1491'\n",
      " 'PAT_36' 'PAT_788' 'PAT_1585' 'PAT_1451' 'PAT_499' 'PAT_311' 'PAT_8'\n",
      " 'PAT_1479' 'PAT_2021' 'PAT_1322' 'PAT_595' 'PAT_1067' 'PAT_1708'\n",
      " 'PAT_558' 'PAT_927' 'PAT_1406' 'PAT_624' 'PAT_386' 'PAT_800' 'PAT_277'\n",
      " 'PAT_1249' 'PAT_934' 'PAT_1531' 'PAT_1365' 'PAT_1349' 'PAT_258' 'PAT_314'\n",
      " 'PAT_959' 'PAT_2053' 'PAT_1529' 'PAT_1892' 'PAT_2119' 'PAT_473'\n",
      " 'PAT_1934' 'PAT_2098' 'PAT_798' 'PAT_2039' 'PAT_1767' 'PAT_325' 'PAT_344'\n",
      " 'PAT_1088' 'PAT_968' 'PAT_717' 'PAT_2105' 'PAT_1066' 'PAT_1308' 'PAT_605'\n",
      " 'PAT_1837' 'PAT_657' 'PAT_810' 'PAT_252' 'PAT_756' 'PAT_1723' 'PAT_918'\n",
      " 'PAT_342' 'PAT_970' 'PAT_1807' 'PAT_245' 'PAT_1569' 'PAT_505' 'PAT_1475'\n",
      " 'PAT_1761' 'PAT_566' 'PAT_787' 'PAT_1534' 'PAT_352' 'PAT_877' 'PAT_565'\n",
      " 'PAT_1940' 'PAT_1746' 'PAT_1468' 'PAT_1563' 'PAT_1177' 'PAT_1046'\n",
      " 'PAT_988' 'PAT_947' 'PAT_893' 'PAT_402' 'PAT_1179' 'PAT_861' 'PAT_477'\n",
      " 'PAT_32' 'PAT_887' 'PAT_1390' 'PAT_1777' 'PAT_632' 'PAT_151' 'PAT_1385'\n",
      " 'PAT_2089' 'PAT_99' 'PAT_2046' 'PAT_1008' 'PAT_668' 'PAT_1441' 'PAT_437'\n",
      " 'PAT_1306' 'PAT_1100' 'PAT_1844' 'PAT_536' 'PAT_368' 'PAT_58' 'PAT_320'\n",
      " 'PAT_1396' 'PAT_1950' 'PAT_324' 'PAT_729' 'PAT_830' 'PAT_1075' 'PAT_10'\n",
      " 'PAT_1026' 'PAT_208' 'PAT_826' 'PAT_1021' 'PAT_2142' 'PAT_423' 'PAT_1244'\n",
      " 'PAT_132' 'PAT_141' 'PAT_964' 'PAT_1822' 'PAT_275' 'PAT_9' 'PAT_989'\n",
      " 'PAT_1482' 'PAT_296' 'PAT_41' 'PAT_165' 'PAT_990' 'PAT_779' 'PAT_1151'\n",
      " 'PAT_915' 'PAT_51' 'PAT_937' 'PAT_2159' 'PAT_1694' 'PAT_453' 'PAT_1495'\n",
      " 'PAT_1345' 'PAT_367' 'PAT_1671' 'PAT_575' 'PAT_383' 'PAT_169' 'PAT_982'\n",
      " 'PAT_574' 'PAT_2152' 'PAT_710' 'PAT_942' 'PAT_1980' 'PAT_1855' 'PAT_484'\n",
      " 'PAT_215' 'PAT_844' 'PAT_2062' 'PAT_1260' 'PAT_767' 'PAT_2070' 'PAT_1466'\n",
      " 'PAT_443' 'PAT_1967' 'PAT_754' 'PAT_1294' 'PAT_491' 'PAT_1714']\n",
      "Fold Accuracy: 0.8630, Fold Precision: 0.8731, Fold Recall: 0.8897\n",
      "\n",
      "Fold 4\n",
      "Train Patients (1099): ['PAT_1516' 'PAT_46' 'PAT_1989' ... 'PAT_491' 'PAT_1343' 'PAT_1714']\n",
      "Test Patients (274): ['PAT_1545' 'PAT_967' 'PAT_38' 'PAT_821' 'PAT_1902' 'PAT_42' 'PAT_79'\n",
      " 'PAT_724' 'PAT_1006' 'PAT_1842' 'PAT_621' 'PAT_620' 'PAT_2051' 'PAT_814'\n",
      " 'PAT_838' 'PAT_882' 'PAT_1884' 'PAT_1276' 'PAT_55' 'PAT_1818' 'PAT_181'\n",
      " 'PAT_714' 'PAT_281' 'PAT_690' 'PAT_1552' 'PAT_1754' 'PAT_118' 'PAT_771'\n",
      " 'PAT_1410' 'PAT_365' 'PAT_63' 'PAT_483' 'PAT_655' 'PAT_1651' 'PAT_1701'\n",
      " 'PAT_747' 'PAT_465' 'PAT_1132' 'PAT_1638' 'PAT_167' 'PAT_243' 'PAT_1821'\n",
      " 'PAT_1547' 'PAT_1658' 'PAT_1013' 'PAT_121' 'PAT_381' 'PAT_1774' 'PAT_952'\n",
      " 'PAT_886' 'PAT_270' 'PAT_585' 'PAT_464' 'PAT_2011' 'PAT_600' 'PAT_1392'\n",
      " 'PAT_1760' 'PAT_1922' 'PAT_161' 'PAT_349' 'PAT_1124' 'PAT_2157'\n",
      " 'PAT_1334' 'PAT_521' 'PAT_2009' 'PAT_1976' 'PAT_757' 'PAT_1472' 'PAT_264'\n",
      " 'PAT_1063' 'PAT_817' 'PAT_255' 'PAT_1947' 'PAT_1402' 'PAT_233' 'PAT_408'\n",
      " 'PAT_109' 'PAT_851' 'PAT_1439' 'PAT_2043' 'PAT_467' 'PAT_101' 'PAT_801'\n",
      " 'PAT_654' 'PAT_996' 'PAT_1036' 'PAT_753' 'PAT_1719' 'PAT_527' 'PAT_1112'\n",
      " 'PAT_416' 'PAT_20' 'PAT_48' 'PAT_746' 'PAT_69' 'PAT_517' 'PAT_2126'\n",
      " 'PAT_1933' 'PAT_1565' 'PAT_864' 'PAT_1699' 'PAT_326' 'PAT_452' 'PAT_155'\n",
      " 'PAT_596' 'PAT_230' 'PAT_366' 'PAT_1611' 'PAT_1399' 'PAT_1812' 'PAT_1198'\n",
      " 'PAT_1731' 'PAT_1170' 'PAT_2131' 'PAT_1280' 'PAT_393' 'PAT_180' 'PAT_188'\n",
      " 'PAT_697' 'PAT_1832' 'PAT_1720' 'PAT_337' 'PAT_1449' 'PAT_401' 'PAT_223'\n",
      " 'PAT_813' 'PAT_735' 'PAT_1477' 'PAT_776' 'PAT_917' 'PAT_2034' 'PAT_287'\n",
      " 'PAT_253' 'PAT_837' 'PAT_709' 'PAT_138' 'PAT_1805' 'PAT_961' 'PAT_97'\n",
      " 'PAT_884' 'PAT_1736' 'PAT_950' 'PAT_649' 'PAT_1618' 'PAT_994' 'PAT_557'\n",
      " 'PAT_841' 'PAT_1022' 'PAT_1370' 'PAT_251' 'PAT_2103' 'PAT_43' 'PAT_370'\n",
      " 'PAT_225' 'PAT_475' 'PAT_1712' 'PAT_1340' 'PAT_1741' 'PAT_954' 'PAT_1288'\n",
      " 'PAT_392' 'PAT_159' 'PAT_1203' 'PAT_150' 'PAT_1555' 'PAT_1727' 'PAT_164'\n",
      " 'PAT_238' 'PAT_1061' 'PAT_852' 'PAT_613' 'PAT_786' 'PAT_1988' 'PAT_313'\n",
      " 'PAT_1186' 'PAT_2030' 'PAT_343' 'PAT_1034' 'PAT_745' 'PAT_1405' 'PAT_260'\n",
      " 'PAT_1570' 'PAT_1246' 'PAT_960' 'PAT_674' 'PAT_534' 'PAT_593' 'PAT_1670'\n",
      " 'PAT_487' 'PAT_1261' 'PAT_678' 'PAT_1603' 'PAT_902' 'PAT_1412' 'PAT_387'\n",
      " 'PAT_2085' 'PAT_688' 'PAT_351' 'PAT_197' 'PAT_955' 'PAT_904' 'PAT_303'\n",
      " 'PAT_1918' 'PAT_1587' 'PAT_936' 'PAT_1284' 'PAT_160' 'PAT_1391' 'PAT_550'\n",
      " 'PAT_1497' 'PAT_667' 'PAT_143' 'PAT_760' 'PAT_135' 'PAT_899' 'PAT_2068'\n",
      " 'PAT_752' 'PAT_507' 'PAT_1427' 'PAT_2151' 'PAT_1484' 'PAT_1960' 'PAT_573'\n",
      " 'PAT_200' 'PAT_1631' 'PAT_1064' 'PAT_1527' 'PAT_229' 'PAT_572' 'PAT_459'\n",
      " 'PAT_70' 'PAT_2109' 'PAT_892' 'PAT_2097' 'PAT_1568' 'PAT_563' 'PAT_1913'\n",
      " 'PAT_978' 'PAT_312' 'PAT_799' 'PAT_1584' 'PAT_1765' 'PAT_1092' 'PAT_933'\n",
      " 'PAT_794' 'PAT_946' 'PAT_1784' 'PAT_1680' 'PAT_604' 'PAT_1538' 'PAT_1833'\n",
      " 'PAT_295' 'PAT_360' 'PAT_1282' 'PAT_1161' 'PAT_187' 'PAT_1854' 'PAT_866'\n",
      " 'PAT_972' 'PAT_716' 'PAT_1332' 'PAT_2079' 'PAT_1185' 'PAT_1520' 'PAT_878'\n",
      " 'PAT_149' 'PAT_113' 'PAT_581' 'PAT_1706' 'PAT_336' 'PAT_1613' 'PAT_1713'\n",
      " 'PAT_498' 'PAT_273']\n",
      "Fold Accuracy: 0.8758, Fold Precision: 0.9167, Fold Recall: 0.8652\n",
      "\n",
      "Fold 5\n",
      "Train Patients (1099): ['PAT_1516' 'PAT_46' 'PAT_1545' ... 'PAT_491' 'PAT_1343' 'PAT_1714']\n",
      "Test Patients (274): ['PAT_1549' 'PAT_117' 'PAT_636' 'PAT_741' 'PAT_380' 'PAT_759' 'PAT_1693'\n",
      " 'PAT_875' 'PAT_1790' 'PAT_107' 'PAT_1431' 'PAT_289' 'PAT_1029' 'PAT_479'\n",
      " 'PAT_236' 'PAT_1381' 'PAT_1984' 'PAT_1255' 'PAT_1278' 'PAT_1710'\n",
      " 'PAT_802' 'PAT_1492' 'PAT_319' 'PAT_796' 'PAT_1730' 'PAT_850' 'PAT_358'\n",
      " 'PAT_792' 'PAT_2008' 'PAT_2042' 'PAT_691' 'PAT_249' 'PAT_458' 'PAT_1089'\n",
      " 'PAT_76' 'PAT_206' 'PAT_1566' 'PAT_1298' 'PAT_373' 'PAT_56' 'PAT_256'\n",
      " 'PAT_115' 'PAT_1125' 'PAT_940' 'PAT_1082' 'PAT_15' 'PAT_1217' 'PAT_2066'\n",
      " 'PAT_1307' 'PAT_1593' 'PAT_666' 'PAT_1071' 'PAT_840' 'PAT_2155' 'PAT_939'\n",
      " 'PAT_1057' 'PAT_145' 'PAT_214' 'PAT_1619' 'PAT_1145' 'PAT_974' 'PAT_580'\n",
      " 'PAT_1945' 'PAT_935' 'PAT_177' 'PAT_497' 'PAT_2125' 'PAT_679' 'PAT_561'\n",
      " 'PAT_770' 'PAT_1554' 'PAT_390' 'PAT_1068' 'PAT_179' 'PAT_726' 'PAT_1181'\n",
      " 'PAT_1326' 'PAT_1347' 'PAT_2050' 'PAT_1330' 'PAT_304' 'PAT_1652'\n",
      " 'PAT_1397' 'PAT_677' 'PAT_90' 'PAT_194' 'PAT_723' 'PAT_35' 'PAT_1715'\n",
      " 'PAT_1369' 'PAT_708' 'PAT_1904' 'PAT_809' 'PAT_400' 'PAT_2102' 'PAT_328'\n",
      " 'PAT_1709' 'PAT_431' 'PAT_1799' 'PAT_1019' 'PAT_571' 'PAT_715' 'PAT_646'\n",
      " 'PAT_219' 'PAT_1448' 'PAT_911' 'PAT_856' 'PAT_835' 'PAT_627' 'PAT_1379'\n",
      " 'PAT_86' 'PAT_812' 'PAT_1314' 'PAT_196' 'PAT_1575' 'PAT_905' 'PAT_294'\n",
      " 'PAT_846' 'PAT_166' 'PAT_664' 'PAT_1404' 'PAT_938' 'PAT_854' 'PAT_528'\n",
      " 'PAT_407' 'PAT_68' 'PAT_1506' 'PAT_154' 'PAT_1415' 'PAT_1707' 'PAT_126'\n",
      " 'PAT_683' 'PAT_122' 'PAT_463' 'PAT_819' 'PAT_152' 'PAT_1521' 'PAT_67'\n",
      " 'PAT_1735' 'PAT_764' 'PAT_862' 'PAT_1418' 'PAT_1551' 'PAT_448' 'PAT_471'\n",
      " 'PAT_379' 'PAT_768' 'PAT_1626' 'PAT_1133' 'PAT_1275' 'PAT_711' 'PAT_457'\n",
      " 'PAT_147' 'PAT_2150' 'PAT_742' 'PAT_1819' 'PAT_1636' 'PAT_1772' 'PAT_269'\n",
      " 'PAT_1377' 'PAT_309' 'PAT_928' 'PAT_506' 'PAT_579' 'PAT_564' 'PAT_719'\n",
      " 'PAT_1536' 'PAT_406' 'PAT_83' 'PAT_1220' 'PAT_901' 'PAT_629' 'PAT_650'\n",
      " 'PAT_626' 'PAT_2093' 'PAT_1975' 'PAT_1698' 'PAT_2108' 'PAT_282'\n",
      " 'PAT_1153' 'PAT_261' 'PAT_110' 'PAT_486' 'PAT_1093' 'PAT_481' 'PAT_1931'\n",
      " 'PAT_1184' 'PAT_1840' 'PAT_1998' 'PAT_891' 'PAT_1705' 'PAT_906'\n",
      " 'PAT_1017' 'PAT_417' 'PAT_530' 'PAT_2026' 'PAT_1407' 'PAT_1315' 'PAT_89'\n",
      " 'PAT_1514' 'PAT_482' 'PAT_656' 'PAT_290' 'PAT_751' 'PAT_516' 'PAT_1543'\n",
      " 'PAT_554' 'PAT_384' 'PAT_698' 'PAT_520' 'PAT_244' 'PAT_240' 'PAT_1264'\n",
      " 'PAT_1882' 'PAT_1300' 'PAT_898' 'PAT_616' 'PAT_611' 'PAT_2162' 'PAT_1722'\n",
      " 'PAT_45' 'PAT_114' 'PAT_62' 'PAT_1753' 'PAT_1309' 'PAT_341' 'PAT_2018'\n",
      " 'PAT_1247' 'PAT_308' 'PAT_541' 'PAT_1594' 'PAT_1869' 'PAT_591' 'PAT_334'\n",
      " 'PAT_1811' 'PAT_883' 'PAT_599' 'PAT_1740' 'PAT_1804' 'PAT_1033'\n",
      " 'PAT_1726' 'PAT_100' 'PAT_318' 'PAT_13' 'PAT_146' 'PAT_986' 'PAT_1464'\n",
      " 'PAT_1241' 'PAT_949' 'PAT_736' 'PAT_687' 'PAT_1107' 'PAT_1051' 'PAT_833'\n",
      " 'PAT_213' 'PAT_2077' 'PAT_1421' 'PAT_562' 'PAT_1850' 'PAT_139' 'PAT_775'\n",
      " 'PAT_1242' 'PAT_488' 'PAT_2082' 'PAT_653' 'PAT_1297' 'PAT_2114' 'PAT_785'\n",
      " 'PAT_695' 'PAT_1513' 'PAT_30' 'PAT_474' 'PAT_1657' 'PAT_190']\n",
      "Fold Accuracy: 0.9063, Fold Precision: 0.9107, Fold Recall: 0.9341\n",
      "\n",
      "Average Accuracy across folds: 0.8764\n",
      "Average Precision across folds: 0.8974\n",
      "Average Recall across folds: 0.8903\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\valan\\OneDrive\\Desktop\\Projects in D Science\\MANDATORY\\metadata.csv\")\n",
    "\n",
    "### **DATA PREPROCESSING** ###\n",
    "binary_cols = ['changed', 'hurt', 'bleed', 'elevation']\n",
    "numeric_cols = ['diameter_1', 'diameter_2', 'age']\n",
    "\n",
    "# Convert categorical columns to numeric (True/False → 1/0, 'UNK' → NaN)\n",
    "df[binary_cols] = df[binary_cols].replace({'True': 1, 'False': 0, 'UNK': np.nan}).astype(float)\n",
    "\n",
    "# Handle missing values:\n",
    "df[binary_cols] = df[binary_cols].fillna(0.5)  # Neutral value for missing binary features\n",
    "df[numeric_cols] = df[numeric_cols].apply(lambda x: x.fillna(x.median()))  # Use median for numeric features\n",
    "\n",
    "# Convert target variable 'biopsed' to numeric (1 = True, 0 = False)\n",
    "df['biopsed'] = df['biopsed'].astype(int)\n",
    "\n",
    "# Select features for the model\n",
    "X = df[binary_cols + numeric_cols].copy()\n",
    "y = df['biopsed']\n",
    "groups = df['patient_id']  # Patient IDs for grouping\n",
    "\n",
    "# Standardize numerical features (KNN is distance-based and sensitive to scale)\n",
    "scaler = StandardScaler()\n",
    "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "\n",
    "### **Ensure Patients Stay in the Same Fold**\n",
    "# Initialize GroupKFold with 5 splits\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "# Perform cross-validation with grouped patients\n",
    "for i, (train_idx, test_idx) in enumerate(gkf.split(X, y, groups)):  # FIX: Correct grouping\n",
    "    # Get train/test patients\n",
    "    train_patients = groups.iloc[train_idx].unique()\n",
    "    test_patients = groups.iloc[test_idx].unique()\n",
    "\n",
    "    print(f\"\\nFold {i + 1}\")\n",
    "    print(f\"Train Patients ({len(train_patients)}): {train_patients}\")\n",
    "    print(f\"Test Patients ({len(test_patients)}): {test_patients}\")\n",
    "\n",
    "    # Check if any patient appears in both sets\n",
    "    repeated_patients = set(train_patients) & set(test_patients)\n",
    "    if repeated_patients:\n",
    "        print(f\"WARNING: These patients appear in both training and testing: {repeated_patients}\")\n",
    "\n",
    "    # Filter dataset so all rows belonging to the selected patients stay in the same fold\n",
    "    train_mask = df['patient_id'].isin(train_patients)\n",
    "    test_mask = df['patient_id'].isin(test_patients)\n",
    "    \n",
    "    X_train, X_test = X[train_mask], X[test_mask]\n",
    "    y_train, y_test = y[train_mask], y[test_mask]\n",
    "\n",
    "    # Train KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)  # Adjust K as needed\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on test set\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    # Evaluate performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "    print(f\"Fold Accuracy: {accuracy:.4f}, Fold Precision: {precision:.4f}, Fold Recall: {recall:.4f}\")\n",
    "\n",
    "# Print final average scores across folds\n",
    "print(f\"\\nAverage Accuracy across folds: {sum(accuracy_scores) / len(accuracy_scores):.4f}\")\n",
    "print(f\"Average Precision across folds: {sum(precision_scores) / len(precision_scores):.4f}\")\n",
    "print(f\"Average Recall across folds: {sum(recall_scores) / len(recall_scores):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
