{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f44589b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2298 entries, 0 to 2297\n",
      "Data columns (total 26 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   patient_id           2298 non-null   object \n",
      " 1   lesion_id            2298 non-null   int64  \n",
      " 2   smoke                1494 non-null   object \n",
      " 3   drink                1494 non-null   object \n",
      " 4   background_father    1480 non-null   object \n",
      " 5   background_mother    1476 non-null   object \n",
      " 6   age                  2298 non-null   int64  \n",
      " 7   pesticide            1494 non-null   object \n",
      " 8   gender               1494 non-null   object \n",
      " 9   skin_cancer_history  1494 non-null   object \n",
      " 10  cancer_history       1494 non-null   object \n",
      " 11  has_piped_water      1494 non-null   object \n",
      " 12  has_sewage_system    1494 non-null   object \n",
      " 13  fitspatrick          1494 non-null   float64\n",
      " 14  region               2298 non-null   object \n",
      " 15  diameter_1           1494 non-null   float64\n",
      " 16  diameter_2           1494 non-null   float64\n",
      " 17  diagnostic           2298 non-null   object \n",
      " 18  itch                 2298 non-null   object \n",
      " 19  grew                 2298 non-null   object \n",
      " 20  hurt                 2298 non-null   object \n",
      " 21  changed              2298 non-null   object \n",
      " 22  bleed                2298 non-null   object \n",
      " 23  elevation            2298 non-null   object \n",
      " 24  img_id               2298 non-null   object \n",
      " 25  biopsed              2298 non-null   bool   \n",
      "dtypes: bool(1), float64(3), int64(2), object(20)\n",
      "memory usage: 451.2+ KB\n",
      "None\n",
      "\n",
      "Missing Values Count:\n",
      " patient_id               0\n",
      "lesion_id                0\n",
      "smoke                  804\n",
      "drink                  804\n",
      "background_father      818\n",
      "background_mother      822\n",
      "age                      0\n",
      "pesticide              804\n",
      "gender                 804\n",
      "skin_cancer_history    804\n",
      "cancer_history         804\n",
      "has_piped_water        804\n",
      "has_sewage_system      804\n",
      "fitspatrick            804\n",
      "region                   0\n",
      "diameter_1             804\n",
      "diameter_2             804\n",
      "diagnostic               0\n",
      "itch                     0\n",
      "grew                     0\n",
      "hurt                     0\n",
      "changed                  0\n",
      "bleed                    0\n",
      "elevation                0\n",
      "img_id                   0\n",
      "biopsed                  0\n",
      "dtype: int64\n",
      "\n",
      "Summary Statistics:\n",
      "          lesion_id          age  fitspatrick   diameter_1   diameter_2\n",
      "count  2298.000000  2298.000000  1494.000000  1494.000000  1494.000000\n",
      "mean   1529.933856    60.464752     2.265730    11.897055     8.852209\n",
      "std    1196.285644    15.894866     0.729029     8.634492     5.797036\n",
      "min       6.000000     6.000000     1.000000     0.000000     0.000000\n",
      "25%     720.500000    52.000000     2.000000     7.000000     5.000000\n",
      "50%    1297.000000    62.000000     2.000000    10.000000     8.000000\n",
      "75%    1782.750000    72.000000     3.000000    15.000000    10.000000\n",
      "max    4820.000000    94.000000     6.000000   100.000000    70.000000\n",
      "\n",
      "Categorical Feature Counts:\n",
      "smoke:\n",
      "smoke\n",
      "False    1292\n",
      "NaN       804\n",
      "True      202\n",
      "Name: count, dtype: int64\n",
      "\n",
      "drink:\n",
      "drink\n",
      "False    1126\n",
      "NaN       804\n",
      "True      368\n",
      "Name: count, dtype: int64\n",
      "\n",
      "itch:\n",
      "itch\n",
      "True     1455\n",
      "False     837\n",
      "UNK         6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "grew:\n",
      "grew\n",
      "False    971\n",
      "True     925\n",
      "UNK      402\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hurt:\n",
      "hurt\n",
      "False    1891\n",
      "True      397\n",
      "UNK        10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "changed:\n",
      "changed\n",
      "False    1700\n",
      "UNK       396\n",
      "True      202\n",
      "Name: count, dtype: int64\n",
      "\n",
      "bleed:\n",
      "bleed\n",
      "False    1678\n",
      "True      614\n",
      "UNK         6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "elevation:\n",
      "elevation\n",
      "True     1433\n",
      "False     863\n",
      "UNK         2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Target Variable Distribution:\n",
      " biopsed\n",
      "True     0.583986\n",
      "False    0.416014\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Feature Correlations:\n",
      " biopsed        1.000000\n",
      "age            0.181797\n",
      "diameter_2     0.081967\n",
      "diameter_1     0.058319\n",
      "fitspatrick   -0.029193\n",
      "lesion_id     -0.526881\n",
      "Name: biopsed, dtype: float64\n",
      "\n",
      "Missing Value Counts:\n",
      "patient_id               0\n",
      "lesion_id                0\n",
      "smoke                  804\n",
      "drink                  804\n",
      "background_father      818\n",
      "background_mother      822\n",
      "age                      0\n",
      "pesticide              804\n",
      "gender                 804\n",
      "skin_cancer_history    804\n",
      "cancer_history         804\n",
      "has_piped_water        804\n",
      "has_sewage_system      804\n",
      "fitspatrick            804\n",
      "region                   0\n",
      "diameter_1             804\n",
      "diameter_2             804\n",
      "diagnostic               0\n",
      "itch                     0\n",
      "grew                     0\n",
      "hurt                     0\n",
      "changed                  0\n",
      "bleed                    0\n",
      "elevation                0\n",
      "img_id                   0\n",
      "biopsed                  0\n",
      "dtype: int64\n",
      "\n",
      "Total rows with missing values in key columns: 804\n",
      "\n",
      "Smoking Data Distribution:\n",
      " smoke\n",
      "False    1292\n",
      "NaN       804\n",
      "True      202\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\valan\\OneDrive\\Desktop\\Projects in D Science\\MANDATORY\\metadata.csv\")\n",
    "\n",
    "### **Step 1: Inspect Basic Information** ###\n",
    "print(df.info())  # Overview of dataset structure\n",
    "print(\"\\nMissing Values Count:\\n\", df.isnull().sum())  # Count missing data for each feature\n",
    "\n",
    "### **Step 2: Summary Statistics for Numerical Features** ###\n",
    "print(\"\\nSummary Statistics:\\n\", df.describe())  # View numerical feature distributions\n",
    "\n",
    "### **Step 3: Distribution of Categorical Features** ###\n",
    "binary_cols = ['smoke', 'drink', 'itch', 'grew', 'hurt', 'changed', 'bleed', 'elevation']\n",
    "print(\"\\nCategorical Feature Counts:\")\n",
    "for col in binary_cols:\n",
    "    print(f\"{col}:\\n{df[col].value_counts(dropna=False)}\\n\")\n",
    "\n",
    "### **Step 4: Check Target Variable (`biopsed`) Distribution** ###\n",
    "print(\"\\nTarget Variable Distribution:\\n\", df['biopsed'].value_counts(normalize=True))\n",
    "\n",
    "### **Step 5: Convert `biopsed` to Numeric for Correlation Analysis** ###\n",
    "df['biopsed'] = df['biopsed'].astype(int)  # Convert boolean to integer (1 = True, 0 = False)\n",
    "\n",
    "### **Step 6: Analyze Correlations (Only Numeric Features)** ###\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "print(\"\\nFeature Correlations:\\n\", df[numeric_cols].corr()['biopsed'].sort_values(ascending=False))\n",
    "\n",
    "### **Step 7: Missing Data Analysis** ###\n",
    "print(\"\\nMissing Value Counts:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check how many rows have missing values in key columns\n",
    "missing_cols = ['smoke', 'drink', 'pesticide', 'gender', 'skin_cancer_history', 'cancer_history',\n",
    "                'has_piped_water', 'has_sewage_system', 'fitspatrick', 'diameter_1', 'diameter_2']\n",
    "missing_rows = df[missing_cols].isnull().any(axis=1).sum()\n",
    "print(f\"\\nTotal rows with missing values in key columns: {missing_rows}\")\n",
    "\n",
    "# Inspect smoking data separately to confirm how missing values behave\n",
    "print(\"\\nSmoking Data Distribution:\\n\", df['smoke'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5f363326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows with missing 'smoke': 804\n",
      "Total rows with missing 'smoke' and 'biopsed' is FALSE: 804\n",
      "\n",
      "Model Accuracy (0.5 for missing binary features): 0.86\n",
      "\n",
      "Feature Importance (Odds Ratios):\n",
      "smoke: 0.07\n",
      "drink: 0.37\n",
      "itch: 1.18\n",
      "grew: 1.72\n",
      "hurt: 7.88\n",
      "changed: 24.85\n",
      "bleed: 4.21\n",
      "elevation: 2.99\n",
      "diameter_1: 1.42\n",
      "diameter_2: 0.94\n",
      "age: 1.40\n",
      "\n",
      "Cross-Validation Accuracy Scores: [0.86521739 0.84130435 0.85869565 0.8496732  0.8496732 ]\n",
      "Mean Accuracy: 0.85\n",
      "\n",
      "Final Missing Value Counts (After Handling):\n",
      "patient_id               0\n",
      "lesion_id                0\n",
      "smoke                    0\n",
      "drink                    0\n",
      "background_father      818\n",
      "background_mother      822\n",
      "age                      0\n",
      "pesticide              804\n",
      "gender                 804\n",
      "skin_cancer_history    804\n",
      "cancer_history         804\n",
      "has_piped_water        804\n",
      "has_sewage_system      804\n",
      "fitspatrick            804\n",
      "region                   0\n",
      "diameter_1               0\n",
      "diameter_2               0\n",
      "diagnostic               0\n",
      "itch                     0\n",
      "grew                     0\n",
      "hurt                     0\n",
      "changed                  0\n",
      "bleed                    0\n",
      "elevation                0\n",
      "img_id                   0\n",
      "biopsed                  0\n",
      "dtype: int64\n",
      "\n",
      "Total rows with missing values in key columns: 804\n",
      "\n",
      "Smoking Data Distribution (After Imputation):\n",
      " smoke\n",
      "0.0    1292\n",
      "0.5     804\n",
      "1.0     202\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valan\\AppData\\Local\\Temp\\ipykernel_25496\\1466051916.py:21: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[binary_cols] = df[binary_cols].replace({'True': 1, 'False': 0, 'UNK': np.nan}).astype(float)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\valan\\OneDrive\\Desktop\\Projects in D Science\\MANDATORY\\metadata.csv\")\n",
    "\n",
    "print(f\"Total rows with missing 'smoke': {df['smoke'].isnull().sum()}\")\n",
    "print(f\"Total rows with missing 'smoke' and 'biopsed' is FALSE: {df[df['smoke'].isnull() & (df['biopsed'] == 0)].shape[0]}\")\n",
    "\n",
    "### **DATA PREPROCESSING** ###\n",
    "\n",
    "# List of categorical features\n",
    "binary_cols = ['smoke', 'drink', 'itch', 'grew', 'hurt', 'changed', 'bleed', 'elevation']\n",
    "numeric_cols = ['diameter_1', 'diameter_2', 'age']\n",
    "\n",
    "# Convert 'UNK' to NaN, then replace True/False with 1/0\n",
    "df[binary_cols] = df[binary_cols].replace({'True': 1, 'False': 0, 'UNK': np.nan}).astype(float)\n",
    "\n",
    "# Fill missing values in binary features with 0.5 (for initial test)\n",
    "df[binary_cols] = df[binary_cols].fillna(0.5)\n",
    "\n",
    "# Fill missing values for numerical features using MEDIAN (to prevent outliers from impacting the data)\n",
    "df[numeric_cols] = df[numeric_cols].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Convert `biopsed` to numeric (1 = True, 0 = False)\n",
    "df['biopsed'] = df['biopsed'].astype(int)\n",
    "\n",
    "# Select features\n",
    "features = binary_cols + numeric_cols\n",
    "X = df[features].copy()\n",
    "y = df['biopsed']\n",
    "\n",
    "# Standardize ONLY numerical features (`diameter_1`, `diameter_2`, `age`)\n",
    "scaler = StandardScaler()\n",
    "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "\n",
    "### **TRAINING LOGISTIC REGRESSION MODEL** ###\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy (0.5 for missing binary features): {accuracy:.2f}\")\n",
    "\n",
    "### **FEATURE IMPORTANCE** ###\n",
    "feature_importance = np.exp(model.coef_[0])  # Convert to odds ratios\n",
    "print(\"\\nFeature Importance (Odds Ratios):\")\n",
    "for feature, importance in zip(X.columns, feature_importance):\n",
    "    print(f\"{feature}: {importance:.2f}\")\n",
    "\n",
    "### **CROSS-VALIDATION** ###\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=None)\n",
    "cv_scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(f\"\\nCross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean Accuracy: {cv_scores.mean():.2f}\")\n",
    "\n",
    "### **MISSING DATA ANALYSIS** ###\n",
    "print(\"\\nFinal Missing Value Counts (After Handling):\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check total rows with missing values in key columns\n",
    "missing_cols = ['pesticide', 'gender', 'skin_cancer_history', 'cancer_history', 'has_piped_water', 'has_sewage_system', \n",
    "                'fitspatrick', 'diameter_1', 'diameter_2']\n",
    "missing_rows = df[missing_cols].isnull().any(axis=1).sum()\n",
    "\n",
    "print(f\"\\nTotal rows with missing values in key columns: {missing_rows}\")\n",
    "\n",
    "# Inspect smoking data distribution after imputation\n",
    "print(\"\\nSmoking Data Distribution (After Imputation):\\n\", df['smoke'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d71fad7",
   "metadata": {},
   "source": [
    "### Splitting the dataset to try to fix the bias of the 804 rows that miss values, and are all biopsed FALSE, which probably would cause issues for our training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "bf077efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.89\n",
      "Cross-Validation Mean Accuracy: 0.89\n",
      "\n",
      "Feature Importance (Odds Ratios):\n",
      "smoke: 2.16\n",
      "drink: 0.73\n",
      "itch: 1.14\n",
      "grew: 1.69\n",
      "hurt: 5.15\n",
      "changed: 18.05\n",
      "bleed: 2.54\n",
      "elevation: 2.82\n",
      "diameter_1: 0.74\n",
      "diameter_2: 1.73\n",
      "age: 0.81\n",
      "\n",
      "Missing Value Counts in Original DataFrame:\n",
      "patient_id               0\n",
      "lesion_id                0\n",
      "smoke                  804\n",
      "drink                  804\n",
      "background_father      818\n",
      "background_mother      822\n",
      "age                      0\n",
      "pesticide              804\n",
      "gender                 804\n",
      "skin_cancer_history    804\n",
      "cancer_history         804\n",
      "has_piped_water        804\n",
      "has_sewage_system      804\n",
      "fitspatrick            804\n",
      "region                   0\n",
      "diameter_1             804\n",
      "diameter_2             804\n",
      "diagnostic               0\n",
      "itch                     0\n",
      "grew                     0\n",
      "hurt                     0\n",
      "changed                  0\n",
      "bleed                    0\n",
      "elevation                0\n",
      "img_id                   0\n",
      "biopsed                  0\n",
      "dtype: int64\n",
      "Test Accuracy: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valan\\AppData\\Local\\Temp\\ipykernel_25496\\1651535331.py:27: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_model[binary_cols] = df_model[binary_cols].replace({'True': 1, 'False': 0, 'UNK': np.nan})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ---------------------------\n",
    "# Load your dataset (adjust the path as needed)\n",
    "df = pd.read_csv(r\"C:\\Users\\valan\\OneDrive\\Desktop\\Projects in D Science\\MANDATORY\\metadata.csv\")\n",
    "\n",
    "# At this point, df remains unchanged so that its missing value counts are preserved.\n",
    "# For example, checking df.isnull().sum() will show that 'smoke' and 'drink' have 804 missing values.\n",
    "\n",
    "# ---------------------------\n",
    "# Now, create a working copy for modeling.\n",
    "df_model = df.copy()\n",
    "\n",
    "# STEP 1: Preprocessing on the modeling copy (df_model)\n",
    "# Define the binary columns (including smoke, drink, etc.)\n",
    "binary_cols = ['smoke', 'drink', 'itch', 'grew', 'hurt', 'changed', 'bleed', 'elevation']\n",
    "\n",
    "# Replace string entries:\n",
    "# - 'True' becomes 1\n",
    "# - 'False' becomes 0\n",
    "# - 'UNK' becomes NaN\n",
    "df_model[binary_cols] = df_model[binary_cols].replace({'True': 1, 'False': 0, 'UNK': np.nan})\n",
    "# Convert them to float and impute missing values with 0.5 (for modeling purposes only)\n",
    "df_model[binary_cols] = df_model[binary_cols].astype(float).fillna(0.5)\n",
    "\n",
    "# Define the numerical columns (we keep diameter_1 and diameter_2 separate, plus age)\n",
    "numeric_cols = ['diameter_1', 'diameter_2', 'age']\n",
    "# Impute missing numerical values with their respective median\n",
    "df_model[numeric_cols] = df_model[numeric_cols].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Convert the target variable 'biopsed' to numeric (True->1, False->0)\n",
    "df_model['biopsed'] = df_model['biopsed'].astype(int)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 2: Use only complete cases for modeling\n",
    "# Define key columns that we require to be present:\n",
    "cols_to_clean = ['pesticide', 'gender', 'skin_cancer_history', 'cancer_history', \n",
    "                 'has_piped_water', 'has_sewage_system', 'fitspatrick', \n",
    "                 'diameter_1', 'diameter_2']\n",
    "\n",
    "# Drop any rows in df_model that are missing a value in any of these key columns.\n",
    "df_clean = df_model.dropna(subset=cols_to_clean)\n",
    "\n",
    "# Now, df_clean contains our complete cases – around 1494 rows.\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 3: Define the features & prepare X and y for training.\n",
    "# Use the binary columns (which include smoke and drink now imputed in df_model) \n",
    "# and the numerical columns.\n",
    "features = binary_cols + numeric_cols\n",
    "\n",
    "X = df_clean[features].copy()\n",
    "y = df_clean['biopsed']\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 4: Standardize only the numerical features.\n",
    "scaler = StandardScaler()\n",
    "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 5: Train the Logistic Regression Model.\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 6: Model Predictions, Evaluation, and Cross-Validation.\n",
    "y_pred = model.predict(X)\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=None)\n",
    "cv_scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "print(f\"Cross-Validation Mean Accuracy: {cv_scores.mean():.2f}\")\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 7: Feature Importance (Odds Ratios)\n",
    "feature_importance = np.exp(model.coef_[0])\n",
    "print(\"\\nFeature Importance (Odds Ratios):\")\n",
    "for feat, imp in zip(X.columns, feature_importance):\n",
    "    print(f\"{feat}: {imp:.2f}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Additional Analysis: Check Missing Value Counts in the Original df.\n",
    "print(\"\\nMissing Value Counts in Original DataFrame:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n",
    "# Split the complete (clean) data into train and test sets (e.g., 80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the hold-out test set\n",
    "y_pred_test = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c560c93e",
   "metadata": {},
   "source": [
    "# **Refining the Model by Selecting Key Features**\n",
    "\n",
    "### **Selected Features**\n",
    "Based on feature importance analysis, we focus on high-impact predictors:\n",
    "\n",
    "| Feature   | Odds Ratio (First Model) | Odds Ratio (Full Model) |\n",
    "|-----------|-------------------------|-------------------------|\n",
    "| **Changed**   | 23.85 | 17.89 |\n",
    "| **Hurt**      | 7.86  | 5.08  |\n",
    "| **Bleed**     | 4.06  | 2.44  |\n",
    "| **Elevation** | 2.94  | 2.89  |\n",
    "| **Diameter**  | 1.24  | 1.26  |\n",
    "| **Age**       | 1.34  | 0.82  |\n",
    "\n",
    "### **Next Steps**\n",
    "1️⃣ **Re-train the model using only the above features**  \n",
    "2️⃣ **Compare accuracy with previous versions**  \n",
    "3️⃣ **Assess if simplifying the model improves generalization**\n",
    "\n",
    "\n",
    "### We split the data into two models before, because for the same 804 entries , we had a lot of missing values. But now that we keep the important features , only diameter has missing values so we ll fix that by using the median for the missing entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "453c0188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8173913043478261\n",
      "Cross-Validation Mean Accuracy: 0.8046045278014589\n",
      "\n",
      "Feature Importance (Odds Ratios):\n",
      "changed: 27.39\n",
      "hurt: 6.71\n",
      "bleed: 5.52\n",
      "elevation: 3.28\n",
      "diameter: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valan\\AppData\\Local\\Temp\\ipykernel_25496\\629157748.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[important_binary] = df[important_binary].replace({'True': 1, 'False': 0, 'UNK': np.nan})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset (adjust file path as needed)\n",
    "df = pd.read_csv(r\"C:\\Users\\valan\\OneDrive\\Desktop\\Projects in D Science\\MANDATORY\\metadata.csv\")\n",
    "\n",
    "# ================================\n",
    "# STEP 1: Preprocess Important Features\n",
    "# ================================\n",
    "\n",
    "# Define important binary features (we use these for the model)\n",
    "important_binary = ['changed', 'hurt', 'bleed', 'elevation']\n",
    "# Replace string values: 'True' becomes 1, 'False' becomes 0, and 'UNK' becomes NaN.\n",
    "df[important_binary] = df[important_binary].replace({'True': 1, 'False': 0, 'UNK': np.nan})\n",
    "# Ensure they are floats, then fill missing values with 0.5\n",
    "df[important_binary] = df[important_binary].astype(float).fillna(0.5)\n",
    "\n",
    "# Process the diameter features.\n",
    "# List of original diameter features\n",
    "diameter_cols = ['diameter_1', 'diameter_2']\n",
    "# Impute missing values with the median for each diameter column.\n",
    "df[diameter_cols] = df[diameter_cols].apply(lambda col: col.fillna(col.median()))\n",
    "# Create a new combined 'diameter' feature as the average\n",
    "df['diameter'] = df[diameter_cols].mean(axis=1)\n",
    "\n",
    "# Convert the target variable 'biopsed' to numeric (True becomes 1, False becomes 0)\n",
    "df['biopsed'] = df['biopsed'].astype(int)\n",
    "\n",
    "# ================================\n",
    "# STEP 2: Define Our Feature Set and Prepare Data\n",
    "# ================================\n",
    "\n",
    "# We are using only the important features:\n",
    "# - The four binary features: changed, hurt, bleed, elevation.\n",
    "# - The combined diameter feature.\n",
    "features = important_binary + ['diameter']\n",
    "\n",
    "# Create our feature matrix X and target y.\n",
    "X = df[features].copy()\n",
    "y = df['biopsed']\n",
    "\n",
    "# Standardize the continuous feature \"diameter\".\n",
    "scaler = StandardScaler()\n",
    "X[['diameter']] = scaler.fit_transform(X[['diameter']])\n",
    "\n",
    "# ================================\n",
    "# STEP 3: Train/Test Split (80/20)\n",
    "# ================================\n",
    "\n",
    "# Split the (processed) dataset into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ================================\n",
    "# STEP 4: Training and Evaluation\n",
    "# ================================\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set.\n",
    "y_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Optionally, you can also perform cross-validation on the entire dataset:\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "print(\"Cross-Validation Mean Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# ================================\n",
    "# STEP 5: Feature Importance (Odds Ratios)\n",
    "# ================================\n",
    "\n",
    "# Calculate the odds ratios (exp(coefficients)).\n",
    "odds_ratios = np.exp(model.coef_[0])\n",
    "print(\"\\nFeature Importance (Odds Ratios):\")\n",
    "for feat, ratio in zip(features, odds_ratios):\n",
    "    print(f\"{feat}: {ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b714af",
   "metadata": {},
   "source": [
    "### And a final training using only the 4 features that seem to be the most important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d53480d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8043478260869565\n",
      "Cross-Validation Mean Accuracy: 0.7932982854977741\n",
      "\n",
      "Feature Importance (Odds Ratios):\n",
      "changed: 27.76\n",
      "hurt: 6.97\n",
      "bleed: 5.76\n",
      "elevation: 3.18\n",
      "\n",
      "Missing Value Counts in Original Data:\n",
      "patient_id               0\n",
      "lesion_id                0\n",
      "smoke                  804\n",
      "drink                  804\n",
      "background_father      818\n",
      "background_mother      822\n",
      "age                      0\n",
      "pesticide              804\n",
      "gender                 804\n",
      "skin_cancer_history    804\n",
      "cancer_history         804\n",
      "has_piped_water        804\n",
      "has_sewage_system      804\n",
      "fitspatrick            804\n",
      "region                   0\n",
      "diameter_1             804\n",
      "diameter_2             804\n",
      "diagnostic               0\n",
      "itch                     0\n",
      "grew                     0\n",
      "hurt                     0\n",
      "changed                  0\n",
      "bleed                    0\n",
      "elevation                0\n",
      "img_id                   0\n",
      "biopsed                  0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valan\\AppData\\Local\\Temp\\ipykernel_25496\\2065590904.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[important_binary] = df[important_binary].replace({'True': 1, 'False': 0, 'UNK': np.nan})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ---------------------------\n",
    "# Load dataset (update the path as needed)\n",
    "df = pd.read_csv(r\"C:\\Users\\valan\\OneDrive\\Desktop\\Projects in D Science\\MANDATORY\\metadata.csv\")\n",
    "# ---------------------------\n",
    "\n",
    "# STEP 1: Preprocessing for the Important Binary Features\n",
    "# We will use only the following features: changed, hurt, bleed, and elevation.\n",
    "important_binary = ['changed', 'hurt', 'bleed', 'elevation']\n",
    "\n",
    "# Replace string entries in these columns:\n",
    "# 'True' becomes 1, 'False' becomes 0, and 'UNK' becomes NaN.\n",
    "df[important_binary] = df[important_binary].replace({'True': 1, 'False': 0, 'UNK': np.nan})\n",
    "# Convert them to float and impute missing values with 0.5 (a neutral value).\n",
    "df[important_binary] = df[important_binary].astype(float).fillna(0.5)\n",
    "\n",
    "# Convert the target variable 'biopsed' to numeric (e.g., True->1, False->0)\n",
    "df['biopsed'] = df['biopsed'].astype(int)\n",
    "\n",
    "# Note: We are intentionally not processing any of the diameter-related features here.\n",
    "\n",
    "# STEP 2: Define Features and Prepare Dataset for Modeling\n",
    "# Our feature set now consists of only the four important binary features.\n",
    "features = important_binary\n",
    "X = df[features].copy()\n",
    "y = df['biopsed']\n",
    "\n",
    "# (Since our binary features have been imputed directly, there is no need for numerical standardization.)\n",
    "\n",
    "# STEP 3: Train–Test Split (using the whole dataset)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# STEP 4: Train the Logistic Regression Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# STEP 5: Evaluate the Model on the Hold-Out Test Set\n",
    "y_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Also run cross-validation on the entire dataset:\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "print(\"Cross-Validation Mean Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# STEP 6: Feature Importance (Odds Ratios)\n",
    "import numpy as np\n",
    "odds_ratios = np.exp(model.coef_[0])\n",
    "print(\"\\nFeature Importance (Odds Ratios):\")\n",
    "for feat, ratio in zip(features, odds_ratios):\n",
    "    print(f\"{feat}: {ratio:.2f}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Additional analysis (optional): Check missingness in the original DataFrame\n",
    "print(\"\\nMissing Value Counts in Original Data:\")\n",
    "print(df.isnull().sum())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
